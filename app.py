import streamlit as st
import fitz  # PyMuPDF
import json
import requests

st.set_page_config(page_title="Agent IA - Appel Ã  projet", layout="centered")

st.title("ğŸ“„ Agent IA - Analyse d'un appel Ã  projet (version gratuite)")

# Chargement du profil associatif
try:
    with open("profil_association.json", "r", encoding="utf-8") as f:
        profil = json.load(f)
except FileNotFoundError:
    st.error("Fichier 'profil_association.json' manquant.")
    st.stop()

# EntrÃ©e du token Hugging Face
hf_token = st.text_input("ğŸ”‘ Token Hugging Face (ne sera pas stockÃ©)", type="password")

# TÃ©lÃ©versement du PDF
uploaded_file = st.file_uploader("ğŸ“ TÃ©lÃ©verser un appel Ã  projet (PDF)", type="pdf")

def lire_pdf(file):
    doc = fitz.open(stream=file.read(), filetype="pdf")
    texte = ""
    for page in doc:
        texte += page.get_text()
    return texte

def interroger_modele_hf(prompt, token):
    API_URL = "https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.1"
    headers = {"Authorization": f"Bearer {token}"}
    payload = {
        "inputs": prompt,
        "parameters": {
            "max_new_tokens": 512,
            "temperature": 0.7
        }
    }
    response = requests.post(API_URL, headers=headers, json=payload)
    if response.status_code == 200:
        return response.json()[0]['generated_text']
    else:
        return f"âŒ Erreur : {response.status_code} - {response.json()}"

if uploaded_file and hf_token:
    texte_pdf = lire_pdf(uploaded_file)

    with st.spinner("ğŸ” Analyse en cours..."):
        prompt = f"""
Tu es un expert des appels Ã  projets pour les associations sportives.

Voici un appel Ã  projet :
-------------------------
{texte_pdf}

Voici le profil de l'association :
-------------------------
{json.dumps(profil, indent=2)}

Analyse l'appel Ã  projet et :
1. RÃ©sume les objectifs, critÃ¨res dâ€™Ã©ligibilitÃ©, Ã©lÃ©ments demandÃ©s, dates importantes.
2. Ã‰value si l'association semble Ã©ligible.
3. Propose un plan de rÃ©ponse en 3 Ã  5 points.
        """

        resultat = interroger_modele_hf(prompt, hf_token)
        st.subheader("ğŸ“Œ RÃ©sultat de l'analyse")
        st.markdown(resultat)
