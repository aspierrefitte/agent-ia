import streamlit as st
import requests
import PyPDF2
import json
import time

st.set_page_config(page_title="Agent IA pour appel Ã  projet", page_icon="ğŸ“„")

st.title("ğŸ“„ Agent IA - RÃ©daction d'appel Ã  projet")
st.write("DÃ©posez un appel Ã  projet au format PDF et le profil de votre association (JSON). L'IA vous gÃ©nÃ¨re automatiquement une proposition adaptÃ©e.")

# Interface utilisateur
hf_token = st.text_input("ğŸ”‘ Entrez votre token Hugging Face", type="password")
uploaded_file = st.file_uploader("ğŸ“ DÃ©posez un appel Ã  projet (PDF)", type="pdf")
profil_file = st.file_uploader("ğŸ“ DÃ©posez le profil de l'association (fichier JSON)", type="json")

# Fonction pour lire le contenu dâ€™un PDF
def lire_pdf(fichier):
    lecteur = PyPDF2.PdfReader(fichier)
    texte = ""
    for page in lecteur.pages:
        texte += page.extract_text()
    return texte

# Fonction pour interroger l'API Hugging Face
def interroger_modele_hf(prompt, token):
    API_URL = "https://api-inference.huggingface.co/models/HuggingFaceH4/zephyr-7b-beta"
    headers = {"Authorization": f"Bearer {token}"}
    payload = {
        "inputs": prompt,
        "parameters": {
            "max_new_tokens": 512,
            "temperature": 0.7
        }
    }

    try:
        response = requests.post(API_URL, headers=headers, json=payload)

        if response.status_code == 503:
            st.warning("â³ Le modÃ¨le se rÃ©veille, rÃ©essai dans 10 secondes...")
            time.sleep(10)
            response = requests.post(API_URL, headers=headers, json=payload)

        if response.status_code == 200:
            resultat = response.json()
            if isinstance(resultat, list) and "generated_text" in resultat[0]:
                return resultat[0]["generated_text"]
            elif isinstance(resultat, list):
                return resultat[0].get("generated_text", "âš ï¸ RÃ©ponse vide.")
            else:
                return f"RÃ©ponse inattendue : {resultat}"
        else:
            return f"âŒ Erreur Hugging Face : code {response.status_code}"

    except Exception as e:
        return f"âŒ Erreur systÃ¨me : {str(e)}"

# Lancement de lâ€™analyse si tous les fichiers sont lÃ 
if uploaded_file and hf_token and profil_file:
    try:
        profil = json.load(profil_file)
    except Exception as e:
        st.error(f"âŒ Erreur lors de la lecture du fichier JSON : {e}")
        st.stop()

    texte_pdf = lire_pdf(uploaded_file)

    prompt = f"""
Tu es un assistant expert en rÃ©daction d'appels Ã  projets associatifs.

Voici un appel Ã  projet :
-------------------------
{texte_pdf}

Voici le profil de l'association :
-------------------------
{json.dumps(profil, indent=2)}

Ta tÃ¢che : 
Propose une **rÃ©ponse structurÃ©e** Ã  cet appel Ã  projet au nom de l'association. Ne fais **aucune analyse**, ne donne pas d'avis, ne fais pas de rÃ©sumÃ©.

Contenu attendu :
- Titre du projet
- Objectifs du projet
- Public visÃ©
- ActivitÃ©s prÃ©vues
- Partenaires Ã©ventuels
- Budget estimÃ© (si possible)
- RÃ©sultats attendus

RÃ©dige de faÃ§on professionnelle, claire et concise.
"""

    with st.spinner("ğŸ› ï¸ GÃ©nÃ©ration de la rÃ©ponse..."):
        resultat = interroger_modele_hf(prompt, hf_token)
        st.subheader("ğŸ“„ Proposition de projet gÃ©nÃ©rÃ©e")
        st.markdown(resultat)
